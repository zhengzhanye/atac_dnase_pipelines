#!/usr/bin/env bds
#vim: syntax=java

// supported file_format : [fastq,bam,tagAlign,bigWig,bedpe]

include "species.bds"
include "log_parser.bds"

help == ENCODE accession settings
string ENCODE_accession = "" 			help ENCODE experiment accession ID (or dataset).
string ENCODE_award_rfa = "" 			help ENCODE award RFA (e.g. ENCODE3).
string ENCODE_assay_category = "" 		help ENCODE assay category.
string ENCODE_assay_title = "" 			help ENCODE assay title.
string ENCODE_award = "" 			help ENCODE award (e.g. /awards/U41HG007000/).
string ENCODE_lab = "" 				help Lab (e.g. /labs/anshul-kundaje/)
string ENCODE_assembly = "" 			help hg19, GRCh38, mm9, mm10.
string ENCODE_alias_prefix = "KLAB_PIPELINE"	help Alias prefix, Alias = alias_prefix: + filename + alias_suffix
string ENCODE_alias_suffix = ""			help Alias suffix, Alias = alias_prefix: + filename + alias_suffix

string[] _summary_qc
string[] _summary_ENCODE_accession
string[] _summary_ENCODE_qc

/*
description 	file_format 	file_format_type 	output_type
raw bam 	bam 					unfiltered alignments
dedup bam  	bam 					alignments
tagAlign 	tagAlign 	bed6			
sig. pval 	bigWig    				signal p-value
sig. fc 	bigWig 	 				fold change over control
n peak 		bed/bigBed	narrowPeak  		filtered peaks
g peak 		bed/bigBed	gappedPeak 		filtered peaks
overlap npeak 	bed/bigBed	narrowPeak		replicated peaks
overlap gpeak 	bed/bigBed	gappedPeak		replicated peaks
idr peak 	bed/bigBed	narrowPeak 		idr thresholded peaks
							optimal idr thresholded peaks
							conservative idr thresholded peaks

*/							

init_ENCODE_accession()

void init_ENCODE_accession() { 
	ENCODE_accession 	= get_conf_val( ENCODE_accession, 	["ENCODE_accession"] )
	ENCODE_award_rfa 	= get_conf_val( ENCODE_award_rfa, 	["ENCODE_award_rfa"] )
	ENCODE_assay_category	= get_conf_val( ENCODE_assay_category, 	["ENCODE_assay_category"] )
	ENCODE_assay_title	= get_conf_val( ENCODE_assay_title, 	["ENCODE_assay_title"] )
	ENCODE_award 		= get_conf_val( ENCODE_award, 		["ENCODE_award"] )
	ENCODE_lab 		= get_conf_val( ENCODE_lab, 		["ENCODE_lab"] )
	ENCODE_assembly		= get_conf_val( ENCODE_assembly, 	["ENCODE_assembly"] )
	ENCODE_alias_prefix	= get_conf_val( ENCODE_alias_prefix, 	["ENCODE_alias_prefix"] )
	ENCODE_alias_suffix	= get_conf_val( ENCODE_alias_suffix, 	["ENCODE_alias_suffix"] )

	print("\n\n== ENCODE accession settings\n")
	print( "ENCODE experiment accession\t: $ENCODE_accession\n" )
	print( "ENCODE award RFA\t\t\t: $ENCODE_award_rfa\n" )
	print( "ENCODE assay category\t\t: $ENCODE_assay_category\n" )
	print( "ENCODE assay title\t\t: $ENCODE_assay_title\n" )
	print( "ENCODE award\t\t\t\t: $ENCODE_award\n" )
	print( "ENCODE lab\t\t\t\t: $ENCODE_lab\n" )
	print( "ENCODE assembly genome\t\t: $ENCODE_assembly\n" )
	print( "ENCODE alias prefix\t\t: $ENCODE_alias_prefix\n" )
	print( "ENCODE alias suffix\t\t: $ENCODE_alias_suffix\n" )
}

void write_summary_json() {

	ret := "{\n"
	ret += "\t\"ENCODE_award_rfa\" : \"" + ENCODE_award_rfa + "\",\n"
	ret += "\t\"ENCODE_assay_category\" : \"" + ENCODE_assay_category + "\",\n"
	ret += "\t\"ENCODE_assay_title\" : \"" + ENCODE_assay_title + "\",\n"
	ret += "\t\"ENCODE_accession\" : \"" + ENCODE_accession + "\",\n"
	ret += "\t\"species\" : \"" + species + "\",\n"
	ret += "\t\"title\" : \"" + title + "\",\n"

	ret += "\t\"data_files\" : [\n"
	cnt := 0
	for ( string json : _summary_ENCODE_accession ) {
		cnt += 1
		cnt2 := 0
		lines := json.split("\n")
		for ( string val : lines ) {
			cnt2 += 1
			ret += ("\t\t"+val+"\n")
			if ( cnt != _summary_ENCODE_accession.size() && cnt2 == lines.size() ) ret += "\t\t,\n"
 		}
	}
	ret += "\t],\n"

	ret += "\t\"qc_files\" : [\n"
	cnt = 0
	for ( string json : _summary_qc ) {
		cnt += 1
		cnt2 := 0
		lines := json.split("\n")
		for ( string val : lines ) {
			cnt2 += 1
			ret += ("\t\t"+val+"\n")
			if ( cnt != _summary_qc.size() && cnt2 == lines.size() ) ret += "\t\t,\n"
 		}
	}
	ret += "\t],\n"
	ret += "\t\"ENCODE_quality_metrics\" : [\n"
	cnt = 0
	for ( string json : _summary_ENCODE_qc ) {
		cnt += 1
		cnt2 := 0
		lines := json.split("\n")
		for ( string val : lines ) {
			cnt2 += 1
			ret += ("\t\t"+val+"\n")
			if ( cnt != _summary_ENCODE_qc.size() && cnt2 == lines.size() ) ret += "\t\t,\n"
 		}
	}
	ret += "\t]\n"

	ret += "}\n"	
	"$out_dir/ENCODE_summary.json".write( ret )
}

void add_ENCODE_metadata_to_summary_json( string file_format, string file_format_type, string output_type, \
	string step_run, \
	string file, string[] derived_from ) {
	json := _get_ENCODE_accession_template( file, derived_from )
	json{"file_format"} = file_format
	if ( file_format_type != "" ) \
		json{"file_format_type"} = file_format_type
	json{"output_type"} = output_type
	json{"file_size"} = file.size()
	if ( step_run != "" ) \
		json{"step_run"} = step_run
	_summary_ENCODE_accession.add( map_to_json_str(json) )
}

//entry of infos can be any string value or filepath (png,pdf,txt...)
void add_ENCODE_quality_metrics_to_summary_json( string ENCODE_qc_type, string step_run, \
						string[] quality_metric_of, string[] logs ) {
	string[] empty
	add_ENCODE_quality_metrics_to_summary_json( ENCODE_qc_type, step_run, quality_metric_of, logs, empty )
}

void add_ENCODE_quality_metrics_to_summary_json( string ENCODE_qc_type, string step_run, \
						string[] quality_metric_of, string[] logs, string[] infos ) {
	string{} json
	// json{"dataset"} = ENCODE_accession // ENCODE experiment accession ID
	json{"award"} = ENCODE_award // ENCODE rfa
	json{"lab"} = ENCODE_lab // lab
	// json{"assembly"} = ENCODE_assembly
	if ( quality_metric_of ) json{"quality_metric_of:array"} = _get_ENCODE_aliases( quality_metric_of )
	if ( step_run ) json{"step_run"} = step_run
	json{"ENCODE_qc_type"} = ENCODE_qc_type
	
	if ( ENCODE_qc_type == "samtools_flagstats_quality_metric" ) { // flagstat (raw)
		//"anshul-kundaje:atac-seq-trim-align-filter-step-run-v1"
		map := parse_log( "flagstat", logs[0] ) // parse flagstat log file
	        json{"diff_chroms"} = map{"diff_chroms"}
	        json{"diff_chroms_qc_failed"} = map{"diff_chroms_qc_failed"}
	        json{"duplicates"} = map{"duplicates"}
	        json{"duplicates_qc_failed"} = map{"duplicates_qc_failed"}
	        json{"mapped"} = map{"mapped"}
	        json{"mapped_pct"} = map{"mapped_pct"}
	        json{"mapped_qc_failed"} = map{"mapped_qc_failed"}
	        json{"paired"} = map{"paired"}
	        json{"paired_properly"} = map{"paired_properly"}
	        json{"paired_properly_pct"} = map{"paired_properly_pct"}
	        json{"paired_properly_qc_failed"} = map{"paired_properly_qc_failed"}
	        json{"paired_qc_failed"} = map{"paired_qc_failed"}
	        json{"read1"} = map{"read1"}
	        json{"read1_qc_failed"} = map{"read1_qc_failed"}
	        json{"read2"} = map{"read2"}
	        json{"read2_qc_failed"} = map{"read2_qc_failed"}
	        json{"singletons"} = map{"singletons"}
	        json{"singletons_pct"} = map{"singletons_pct"}
	        json{"singletons_qc_failed"} = map{"singletons_qc_failed"}
	        json{"total"} = map{"total"}
	        json{"total_qc_failed"} = map{"total_qc_failed"}
	        json{"with_itself"} = map{"with_itself"}
	        json{"with_itself_qc_failed"} = map{"with_itself_qc_failed"}
	}
	else if ( ENCODE_qc_type == "complexity_xcorr_quality_metric" ) { // xcor + pbc
		//"anshul-kundaje:atac-seq-trim-align-filter-step-run-v1"
		map_pbc := parse_log( "pbc", logs[0] )
		map_xcor := parse_log( "xcor", logs[1] )
		json{"NSC"} = map_xcor{"NSC"}
		json{"RSC"} = map_xcor{"RSC"}
		json{"fragment length"} = map_xcor{"est_frag_len"}
		json{"PBC1"} = map_pbc{"PBC1"}
		json{"PBC2"} = map_pbc{"PBC2"}
		json{"NRF"} = map_pbc{"NRF"}
		json{"sample size"} = map_xcor{"num_reads"}
		json{"paired-end"} = infos[0]
		json{"cross_correlation_plot"} = infos[1] //xcor_plot
		json{"read length"} = (logs[2]).readLines()[0]
	}
	else if ( ENCODE_qc_type == "idr_quality_metric" ) {
		//"anshul-kundaje:atac-seq-idr-step-run-v1"
		map := parse_log( "idr", logs[0] )
		json{"IDR_cutoff"} = infos[0]
		json{"N1"} = map{"N1"}
		if ( parse_real(map{"rescue_ratio"}) > 0.0 ) { // for two-replicate case, 
			json{"rescue_ratio"} = map{"rescue_ratio"}
			json{"Np"} = map{"Np"}
			json{"Nt"} = map{"Nt"}
			json{"N2"} = map{"N2"}
			json{"N_optimal"} = map{"N_opt"}
			json{"N_conservative"} = map{"N_consv"}
			json{"self_consistency_ratio"} = map{"self_consistency_ratio"}
			json{"reproducibility_test"} = map{"reproducibility_test"}
		}
		if ( infos[1] ) json{"IDR_plot_true"} = infos[1]
		if ( infos[2] ) json{"IDR_plot_rep1_pr"} = infos[2]
		if ( infos[3] ) json{"IDR_plot_rep2_pr"} = infos[3]
		if ( infos[4] ) json{"IDR_plot_pool_pr"} = infos[4]
		if ( infos[5] ) json{"IDR_parameters_true"} = infos[5] // idr_log (*.log.txt)
		if ( infos[6] ) json{"IDR_parameters_rep1_pr"} = infos[6]
		if ( infos[7] ) json{"IDR_parameters_rep2_pr"} = infos[7]
		if ( infos[8] ) json{"IDR_parameters_pool_pr"} = infos[8]
		if ( logs[1] ) json{"Fp"} = (logs[1]).readLines()[0]
		if ( logs[2] ) json{"Ft"} = (logs[2]).readLines()[0]
		if ( logs[3] ) json{"F1"} = (logs[3]).readLines()[0]
		if ( logs[4] ) json{"F2"} = (logs[4]).readLines()[0]
	}
	else if ( ENCODE_qc_type == "overlap_quality_metric" ) {
		
		map := parse_log( "idr", logs[0] )
		json{"N1"} = map{"N1"}
		if ( parse_real(map{"rescue_ratio"}) > 0.0 ) { // for two-replicate case, 
			json{"rescue_ratio"} = map{"rescue_ratio"}
			json{"Np"} = map{"Np"}
			json{"Nt"} = map{"Nt"}
			json{"N2"} = map{"N2"}
			json{"N_optimal"} = map{"N_opt"}
			json{"N_conservative"} = map{"N_consv"}
			json{"self_consistency_ratio"} = map{"self_consistency_ratio"}
			json{"reproducibility_test"} = map{"reproducibility_test"}
		}
		if ( logs[1] ) json{"Fp"} = (logs[1]).readLines()[0]
		if ( logs[2] ) json{"Ft"} = (logs[2]).readLines()[0]
		if ( logs[3] ) json{"F1"} = (logs[3]).readLines()[0]
		if ( logs[4] ) json{"F2"} = (logs[4]).readLines()[0]
	}
	else if ( ENCODE_qc_type == "generic_quality_metric" ) {
		json{"name"} = "$ENCODE_accession:All calculated QC"
		json{"attachment"} = logs[0]
	}
	else {
		error("Unsupported ENCODE_qc_type ($ENCODE_qc_type)!\n")
	}

	_summary_ENCODE_qc.add( map_to_json_str(json) )	
}

string _get_ENCODE_aliases( string[] derived_from ) {
	// derived_from	
	string[] arr
	for ( string file : derived_from ) {
		if ( get_basename(file).startsWith("ENCF") && file.indexOf(".fastq.gz") > -1 ) {
			// for fastqs, their file name prefixes are accesion IDs
			file2 := get_basename(file).replace(".trim","").split(".fastq.gz")[0]
			if ( file2.indexOf("_") > 0 ) {
				arr.add( file2.split("_")[0] )
				arr.add( file2.split("_")[1] )
			}
			else {
				arr.add( file2 )
			}
		}
		else {
			map_derived_from := _read_metadata( file ) 
			arr.add( (map_derived_from{"aliases:array"}).replace("[","").replace("]","") )
		}
	}
	return arr.size() ? ("[" + array_to_str(arr,";") + "]") : ""
}

string{} _get_ENCODE_accession_template( string file, string[] derived_from ) {
	map := _read_metadata( file )
	map{"derived_from:array"} = _get_ENCODE_aliases( derived_from )
	return map
}

// basic ENCODE data are stored in .meta file
string{} _read_metadata( string file ) { // read from .meta and write to a map 
	string{} map
	meta_o_dir := mkdir("$out_dir/meta")
	// read .meta file if exists (format: conf in conf.bds, contents: md5sum, ...)
	meta_file := replace_dir( file, meta_o_dir ) + ".meta"
	if ( path_exists( meta_file ) && !(meta_file<-file) ) {
		map = read_conf( meta_file, "" )
	}
	else {
		map{"md5sum"} = get_md5sum( file )
	}
	map{"submitted_file_name"} = get_basename(file)
	map{"dataset"} = ENCODE_accession // ENCODE experiment accession ID
	map{"award"} = ENCODE_award // ENCODE rfa
	map{"lab"} = ENCODE_lab // lab
	map{"assembly"} = ENCODE_assembly
	map{"aliases:array"} = "[$ENCODE_alias_prefix:" + get_basename(file) + "$ENCODE_alias_suffix]"
	meta_file.write( map_to_conf_str(map) )

	return map
}
